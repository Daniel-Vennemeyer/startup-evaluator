Project Title,Submission Url,Project Status,Judging Status,Highest Step Completed,Project Created At,About The Project,"""Try it out"" Links",Video Demo Link,Opt-In Prizes,Built With,Notes,Team Colleges/Universities,Additional Team Member Count,What Table Are You At?,Mlh Points,Mlh Software Lab,Mlh Hardware Lab
knowledge kiosk,https://revuc-vii.devpost.com/submissions/89653-knowledge-kiosk,Submitted (Gallery/Visible),Pending,,03/04/2018 05:46:45,"Inspiration

We wanted to create something to solve the lack of availability of knowledge in the world

What it does

You enter a word and it outputs a definition for it (want to add much more but 24 hours is not nearly enough time to implement everything that we want to add)

How I built it

We used an arduino 101 with 4 grove kit buttons and a grove kit lcd for the hardware side, and used the official arduino IDE for the software and programming side

Challenges I ran into

An array was not acting how I wanted it to, getting the lcd to work was a pain, installing the libraries for the arduino 101 took about an hour, taking away from our time, it was hard to find a way to mount the buttons and display effectively so they could be used in a cognitive manner

Accomplishments that I'm proud of

Getting a cursor to appear over letters and disappear when moved away from them, dealing with the lack of a full keyboard to input text by manually selecting letters with directional keys, manually inputting every single word included in the project for presenting

What I learned

We had never written my own code for an arduino before this. We learned how to interface with basic grove components and figured everything out by using one example program. We also learned some of the most common words in the English language

What's next for knowledge kiosk

We will continue to add features to the knowledge kiosk over time like a translator, more complete button interface, better display, possible integration with a raspberry pi, etc.
",https://gist.github.com/jvhbv/22deaaf2e4a76ee3c55a6907fca43c75,https://youtu.be/M8QJgVCo0hc,"Best Education Hack, Best High School Hack","arduino, grove",,"",0,8603-D,Purcell Marian High School,"","Arduino 101, Base Shield, and Grove Starter Kit Components"
Dead Pixels,https://revuc-vii.devpost.com/submissions/89668-dead-pixels,Submitted (Gallery/Visible),Pending,,03/04/2018 07:29:16,"
Useless hack - I wanted to make something annoying, inconvenient, and stupid at the same time.
Makes your pixels white.
Made with: Java & caffiene
Problems: Lots of windows. But hey, makes it more useless.
Learned: It's so annoying & That I have no goal here except to do homework really
Future?: Push to github, leave it there.

",https://github.uc.edu/lambricm/DeadPixels,,Best Useless Hack,java,,University of Cincinnati,0,801B-1,University of Cincinnati,"",""
SecureAWS,https://revuc-vii.devpost.com/submissions/89669-secureaws,Submitted (Gallery/Visible),Pending,,03/04/2018 07:36:23,"Inspiration

In the recent times, we find news about AWS breaches leading to TB's of data and compromised ec2 instances used for cryptocurrency, etc. Majority of the AWS breaches happen due to human error which leads to deviation from configuration standards and limited understanding of AWS shared responsibility model. I wanted to create an Alexa skill which would get your security Data to you without the need of logging in or running scripts. 



What it does

It runs security assessments based on industry-accepted practices to provide an overview of existing benchmarks which will allow evaluating the security of the account consistently.  Alexa gets the security data and provides analysis based on user's question. For example, when the user asks Alexa ""how secure is my amazon environment,"" it returns with some failed tests, passed tests and manual tests which needed user inspection. The user can also request reasons for failures by asking ""why did the tests fail,"" and Alexa returns all the reasons for failed tests.



How I built it

The primary data source is generated by AWS CIS benchmark script run periodically and stored in JSON format. Created an API routes using Flask which is integrated with Alexa intents and provide HTTPS end point for Alexa to talk to. Configured Alexa skill set to communicate with the HTTPS with custom metrics and questions mapped to each intent.



Challenges I ran into


learning Alexa
developing using intents on flask-asks
Dealing with unserialized JSON data




Accomplishments that I am proud of

I think it is the first Alexa skill which would gather security configuration information of an AWS environment based and provide an overview of the configurations.



What I learned

learned how to make skills on Alexa, new open sources technologies like ngork, flask, flask-ask.



What's next for SecureAWS

Will be creating a standalone lambda script which would directly communicate with the alexa based on actions so that way the configuration data wouldn't leave the aws premises. My primary Goal for SecureAWS is to create custom metrics on the AWS environment which would increase the visibility for changes and allows you to monitor the environment more effectively.
",https://github.com/nvvarma19/RevolutionUC_SecureAWS,https://www.youtube.com/watch?v=sr44e4eFvNU,"JP Morgan Chase & Co. - Best Hack for Social Good, Fifth Third Bank - Best Fin Tech Solution, Best Education Hack, Best Useless Hack, 8451 - Make the Customer's Life Easier, Amazon Web Services - Best Use of AWS","python, flask, amazon-web-services, alexa",,University of Cincinnati,0,801-9,university of Cincinnati,AWS,Amazon Echo
Digital Forensic Linguistics,https://revuc-vii.devpost.com/submissions/89671-digital-forensic-linguistics,Submitted (Gallery/Visible),Pending,,03/04/2018 07:43:45,"Inspiration

The field of digital forensic linguistics is influenced greatly by its sister field of forensic linguisticsâ€”the application of linguistics to legal issues. Examples of such usage include an appeal against the conviction of Derek Bentley the identification of Subcomandante Marcos, the Zapatistas' charismatic leader by Max Appedole, and, perhaps most famously, the identification of Theodore Kaczynski as the so-called ""Unabomber"" by James R. Fitzgerald.

In the digital world, anonymity is both a blessing and a curse. It allows discussion of ideas without fear of persecution, but also perpetuation of terrible crimes without fear of retribution. Digital forensic linguistics, like its sister field, uses idiosyncrasies of digital languages, programming languages specifically, to identify demographic information about individuals, such as gender, approximate age, and location.

What it does

The digital forensic linguistics toolkit uses random sampling of GitHub users to create a dataset from which a model is extracted, ultimately connecting inputs (information about the user's programs) to outputs (demographic information about the user).

How I built it

The toolkit was built simply by integrating existing API frameworks from GitHub and Microsoft, then chaining those together with feature extraction mechanisms. After that, the evaluation metrics utilizing scikit-learn machine learning package were designed.

Challenges I ran into


Getting access to GitHub's API and Microsoft's Face API and not surpassing strict rate limits (couldn't afford to get banned)
Downloading nearly 60 GB of GitHub repositories
Parsing through those repositories quickly
Picking a machine learning model


Accomplishments that I'm proud of


Not getting banned from any of the API systems I used!
Using Microsoft's Face API successfully
Getting any machine learning model to actually work
Getting any kind of product done
Predicting mustache presence (albeit poorly)


What I learned

Usage of Microsoft's Azure Face API is relatively easy, but scarily accurate, even with low resolution faces. Additionally, natural language and programming language predictions are fairly easy given existing Python architectures.

Choosing a machine learning algorithm is an exceedingly complicated task. Different algorithms are best under certain conditions, and patterns you can could be due to various confounds or other factors. In short, when using machine learning methods, be extremely careful.

What's next for Digital Forensic Linguistics

While the system boats some decent accuracy and explained variance scores, it is not complete, as there were several input types I considered, but did not end up having time to completely implement. Further, a complete review of machine learning methodologies was (understandably) rushed, leaving out several which could have been more useful than those utilized in the end.

Hopefully, the system will be able to begin identifying individuals who have written various infamous virus programs. This will be a true test of the idea's efficacy. Additionally, a much larger sample of programmers will be necessary to continue forward.
",https://github.com/Superraptor/digital_forensic_linguistics_toolkit,,"","python, azure, github, api, scikit-learn",,University of Cincinnati,0,801C-3,University of Cincinnati,"",""
prepr,https://revuc-vii.devpost.com/submissions/89690-prepr,Submitted (Gallery/Visible),Pending,,03/04/2018 08:45:26,"Prepr

This app is aimed towards meal preppers. Meal preppers are people who like to prepare all of their food for the week on one day. This system is perfect for college students because it helps them save time and money by being more conscious about the food that they buy and cook for themselves. 

The idea behind this app is to provide an easy platform for meal preppers to manage their favorite recipes and convert them into handy shopping lists. Through the app you can add your favorite recipes, which can be automatically added to a shopping list along with an easy to follow list of instructions for preparing your food.
",https://github.com/newswangerd/prepr,,"JP Morgan Chase & Co. - Best Hack for Social Good, 8451 - Make the Customer's Life Easier",javascript,,Berea College,2,860B-3,Berea College,"",""
KillChainBot,https://revuc-vii.devpost.com/submissions/89730-killchainbot,Submitted (Gallery/Visible),Pending,,03/04/2018 09:26:37,"Inspiration

Our passion for cyber security

What it does

It automates the kill chain from surveillance to reconnaissance to exploitation and payload delivery while sustaining the integregrity and security of itself.

How I built it

We configured and Ubuntu image to run on a raspberry pi with suricata intrusion detection and prevention system set up to monitor and defend it's own hosted network. Meanwhile we made use of many different hacking tools in the kill chain and automated the use of these tools with python.

Challenges I ran into

Configuring the system to run correctly with an acceptable os and IDS/IPS has been the hardest issue.

What I learned

We learned a lot about managing and coordinating many tools to work together
","",,"","raspberry-pi, aircrack-suit, suricata, nmap, python, linux, ubuntu, network-analysis-tools-(neat), metasploit, atomation, json",,University of Cincinnati,0,Room 1000,University of Cincinnati,"",""
LendMe,https://revuc-vii.devpost.com/submissions/89732-lendme,Submitted (Gallery/Visible),Pending,,03/04/2018 09:35:23,"Inspiration

We want to provide a service that'll allow people to request small loans of money from other users on the platform, all while keeping each user anonymous and secure when sending and requesting money.

What it does

This service allows for users to obtain small loans from people who would like to grow their money in a fast way. The lender is in full control setting the interest amount, payback period, and acceptance of someone taking the loan, making fast money has never been safer. We utilize blockchain technology to secure our network along with AI systems that monitor the service around the clock and immediately take action if needed. We integrate better than bank level security which keeps hackers out and your data and money safe.

How we built it

We built the Android App using Java within Android studio
We built the website using HTML, CSS, JavaScript, along with connecting to a firebase database to keep information synced across the web and mobile sites.

Challenges we ran into

We ran into some challenges with getting JavaScript to load certain functions, along with Firebase responding to our Query commands so we could retrieve the data we were seeking. 

Accomplishments that we're proud of

I think we are all very proud of the fact that we were able to complete an idea that could be revolutionary, if we think about it bank technology is old and outdated, this is why they are constantly getting hacked. So we figured why not create a new platform using the newest technology that has had a proven track record of keeping data safe and in tact without modification. This also decentralizes the money loaning system from just banks to everyday people.

What we learned

JavaScript is absolutely a nightmare. No really, a nightmare. 10/10 would not recommend 

What's next for LendMe

Fingerprint support, Support for Multiple Languages, Figuring out how to reduce operating costs to get more money in customers hands, Better AI technology that secures the network even more, More sign in options making it more flexible for our customers and Lenders.
","",,"JP Morgan Chase & Co. - Best Hack for Social Good, Fifth Third Bank - Best Fin Tech Solution, 8451 - Make the Customer's Life Easier, Best Domain Name from Domain.com","javascript, java, html, css, firebase, database, dns, domain.com, curl",,"Unversity Of Cincinnati, University of Cincinnati",2,801B-5,University Of Cincinnati,"",""
GreenLight,https://revuc-vii.devpost.com/submissions/89735-greenlight,Submitted (Gallery/Visible),Pending,,03/04/2018 09:39:31,"Inspiration: As a retired veteran one of my biggest stresses leaving active duty was trying to find the resources I needed. this app is a way for me to insure my brothers and sisters in arms will never leave their service feeling lost.

What it does:  GreenLight will allow a veteran to anonymously enter their zipcode and find not only available resources but also give them a contact to reach out to in order to expedite the veteran getting the help they need.

How I built it:  We started by making a database of contact information and resources for veterans as well as a list of zipcodes and then put that database into a simple site for veterans to be able to access and use.

Challenges I ran into: The first challenge we ran into was getting all the information for the resources, the next big issue was deciding to change from PHP to ASP.

Accomplishments that I'm proud of:  We are proud that we where able to pool our knowledge and write this site in a language we where not familiar with and on a personal note I like making something that can honestly improve the lives of men and women who to often fail to find help because they don't know where to look.

What I learned:  We learned a great deal about Amazon.AWS as well as ASP

What's next for GreenLight:  Ultimately the plan would be to expand the database to add more contact information for more areas to assist a wider range of service members.
","",,"JP Morgan Chase & Co. - Best Hack for Social Good, Best Education Hack, 8451 - Make the Customer's Life Easier, Amazon Web Services - Best Use of AWS","asp.net, bootstrap, jquery, zipcodeapi.com, sql, amazon-web-services",,University of Cincinnati Clermont College,0,801M-1,University of Cincinnati Clermont,AWS,""
PollMe,https://revuc-vii.devpost.com/submissions/89737-pollme,Submitted (Gallery/Visible),Pending,,03/04/2018 09:40:18,"PollMe

An open source solution that allows for mid-presentation interaction between attendees and presenters through SMS

Inspiration

At the University of Tennessee, we are required to have a Turning Point Technology ""clicker"" to answer mid-lecture questions in many lower-level classes. The problem with this system is that we not only have to pay for the clicker, but we also have to pay for a yearly subscription to Turning Point. We feel almost scammed because of the amount of money we have to pay for this, so we decided to come up with a free option that doesn't require extra hardware and that doesn't require any subscription, and that scales to be applicable to any type of meeting or conference with a speaker. In addition, we saw this as an opportunity to improve the way students or other meeting attendees interact with the professor or speaker. There's always people in large lectures that want to ask questions but that are either too shy or too worried about sounding stupid, and there's also the problem that a professor in a large lecture wants to wait for a natural pause before answering questions instead of stopping mid-stream. To solve these problems, we've added capability to PollMe to allow people to submit anonymous questions real-time to the professor or speaker.

What it does

Anyone can set up an account to put out polls in a class or meeting; the attendees just have to send a text to the app's phone number with a header to identify the class section and poll. The presenter then can see real-time results of how attendees answered. Similarly, if someone has a question, instead of having to raise their hand and ask it in front of a large group of people, they can send a text with a header identifying the class section or meeting, and the professor can receive that real-time.

How we built it

We're hosting this project on an AWS-ec2 instance. We're using flask and docker builds on the backend, and we're using Twilio's API to send and receive SMS's.

Challenges we ran into

We started out trying to use a different SMS API, but it turned out to be anti-user-friendly. Also, figuring out how to receive a text in Twilio wasn't the easiest thing in the world. We realized that docker doesn't work correctly on the Ubuntu subsystem for Windows 10; it wasn't a huge problem, but it meant some work that should've been done locally had to happen on the server. We also got a little bit of a slow start and started to get fairly time-constrained towards the end.

What we learned

Most of our group had never worked with an SMS API, so using Twilio was a good learning experience. API endpoints were also new to most of us.

What's next for PollMe

We would like to add the option for students/attendees to interact with the app via web instead of forcing SMS, but we just didn't have the time for that at this hackathon.
","",,"JP Morgan Chase & Co. - Best Hack for Social Good, Best Education Hack, Best Useless Hack, 8451 - Make the Customer's Life Easier, Amazon Web Services - Best Use of AWS, Best Domain Name from Domain.com","javascript, css, html, docker, python, twilio, flask, jquery, mysql, ubuntu, amazon-ec2, amazon-web-services",,The University of Tennessee - Knoxville,3,801D-3,University of Tennessee,AWS and Domain.com,""
OpenFund,https://revuc-vii.devpost.com/submissions/89738-openfund,Submitted (Gallery/Visible),Pending,,03/04/2018 09:49:11,"Inspiration

I am constantly being told about the shrinking of middle class, but rarely hear any viable solutions.

This weekend I wanted to save the middle class.

Apparently the average middle class American saves about 4.4% of their income. Of course we know we should always save more--but I was struck by the fact that the average middle class American is saving. One common theme in analyses is that when the people of the middle class invest, they don't know what they're investing for. While those above a certain financial threshold can afford financial advisers and tax accountants, the middle class often lacks a goal or an objective.

This asymmetry leaves those who work hard in the middle class to struggle and fail to improve their financial position.

What it does

OpenFund is a platform where anyone can come to make their financial goals real, and use open source investing algorithms to make financial independence attainable.

How I built it

OpenFund is built on top of a Django web framework that is built for easy extensibility. This allows open source contributors to build their own trading algorithms in a modular way, and then seamlessly publish them for anyone to use.

Challenges I ran into

Financial math can be hard! I was super luck to have the help of a couple JP Morgan and 5th/3rd mentors to help me figure out what was important and get the math right.

Accomplishments that I'm proud of

I wrote my first ever unit tests! (Maybe proud and embarrassed it took this long)
I learned a metric heck ton about finance and asset management!
I worked on something I care about that can help people!

What I learned

I learned so very very much about finance and investing. I learned a lot about understanding the end user and focusing on what will bring value to their lives. I learned quite about Django, and SQL databases.

What's next for OpenFund

I want to work out a few of the kinks so it's actually running. The sick thing about 
",https://github.com/wlifferth/openfund,,"JP Morgan Chase & Co. - Best Hack for Social Good, Fifth Third Bank - Best Fin Tech Solution, Best Education Hack","django, python, heroku, d3.js, jquery, photoshop, sqlite",,The University of Tennessee - Knoxville,0,801D-1,University of Tennessee,"",""
OpenLab,https://revuc-vii.devpost.com/submissions/89742-openlab,Submitted (Gallery/Visible),Pending,,03/04/2018 09:57:05,"Inspiration

My group came into this hackathon with eager hearts and empty heads. We all knew that we wanted to learn from making something during this event, but we didn't know what. We went on a brainstorm walk, which led us to walk through the university chemistry lab building. This gave us the inspiration to create a particle-based chemistry simulation.

What it does

As rudimentary as it is, this simulates an a chemical reaction, which we believe would help benefit lower income schools as well as providing a safe environment to safely mix in chemicals and simulate them. Some examples, include combustion and acid-base reactions. 

How I built it

We split up the tasks and all spent maybe at least 3 hours trying to figure out what to do and how to get things to work together.

Challenges I ran into

We ran into numerous problems: we had no experience with unity, 3d modeling, working with  a physics engine, coding in the physics, and  no one had any experience with a gaming engine.

Accomplishments that I'm proud of

We got it to work, all together.

What I learned

We learned, that it was rather difficult to get all the components working together properly. As well as how some components may not even be necessary.

What's next for OpenLab

We hope to make further progress in enriching our curious minds for the sake of the future for the children.
",https://drive.google.com/file/d/1B6nt1BjGdsshtM3I3e8bJXFI5kq2QnC2/view,,"JP Morgan Chase & Co. - Best Hack for Social Good, Best Education Hack","adobe-illustrator, unity, c#",,University of Cincinnati,0,801-2,Univeristy of Cincinnati - Sinclair Community College,"",Oculus Rift
Secure Drawer,https://revuc-vii.devpost.com/submissions/89744-secure-drawer,Submitted (Gallery/Visible),Pending,,03/04/2018 10:06:44,"Inspiration

With most lock boxes, you need to use something like a key, RFID, or something else that you gotta keep track of to open the device.  

We wanted to make something that was effortless to get access to the secured box.  With Bluetooth Low Energy (BLE), we can auto unlock the box which makes for a convenient and secure device!

What it does

Our security drawer has many features to protect your stuff.  We have it locked with a servo.  If your phone is near the device (within a foot or two), it will automatically unlock the drawer and you can open it with ease.

However, if you are NOT an authorized user, the drawer will be locked.  If you try to pick up the box, an alarm to go off and there will be red lights flashing!  This will scare anyone trying to take the box.

How we built it

The drawer is made out of foam board and cardboard with an acrylic handle.  It has a servo on the inside to handle locking and unlocking.

Inside there is a board with several devices.  We have an Arduino pro mini that controls the LEDs and servo.  We also have a 9 degree of freedom sensor to measure force on the box.  In addition a BLE module is connected to be able to broadcast out to devices.

A service runs on an Android phone that periodically checks for the drawer.  If the drawer is nearby, it will start monitoring RSSI (signal strength).  Once close enough, the phone sends the unlock command and the drawer will open.  Once out of range, the drawer will lock.

Challenges we ran into

We ran out of wire and had to improvise a couple times.

We burned some stuff (only 2 fires this time!)

We shocked some stuff (but nothing actually broke!)

The BLE module purchased ended up actually being a cheap knockoff with very little functionality.  We had to rethink our method of attack to get the project to work.  We had to decompile someone elses Android application to figure out how to write our own to interface with the BLE device correctly.

Accomplishments that we're proud of

You can actually authenticate with your phone locked AND in your pocket.  It actually is a 0 effort solution!

What we learned

If you are working with an unknown BLE device, a BLE packet sniffer would be super helpful.

Bring enough wire for your project.

As always, hardware IS hard.

Zener diodes dont work well on data lines.

What's next for Secure Drawer

Upgrading to a drawer that you can't cut a hole in.

A smaller form factor for the device.  Ideally, we would like to be able to adapt it to any drawer.

Be wealthy enough to have valuable items to keep safe in our drawer.
","",https://youtu.be/_EFg5OU0XbE,TCS - Best Hardware Hack,"c++, arduino, android, java, bluetooth, ble, leds, foam-board, chinesium, raspberry-pi",,"University of Akron, Ohio State University",3,860D-3,"University of Akron, The Ohio State University","",""
Focus Friend,https://revuc-vii.devpost.com/submissions/89753-focus-friend,Submitted (Gallery/Visible),Pending,,03/04/2018 10:28:39,"Inspiration

In previous years at RevolutionUC, we have been enthralled by all the different hardware and we were determined to use the Muse brainwave-sensing headband this year. Therefore, we decided to center our project around a problem that we see in everyday life, and incorporating a solution that will be the most beneficial to the most users. 

ADHD is the single most common childhood disorder with nearly 11% of school age children having been diagnosed. As the cases in the country have incresed in the last few years, we decided it would be appropriate to look at this issue through a digital lens. 

Our Project

Our project leverages the Muse Headband to detect levels of gamma brain-wave activity, and creates a graphical display that allows patients to learn how to control their thought patterns through biofeedback. In biofeedback, an individual monitors a real-time display of a body mesurement and consciously makes an effort to change it. By exercising this way, they learn how to consciously control what would otherwise be an unconsciously controlled bodily function.

While biofeedback is clasically applied to physiological metrics like blood preasure and heart rate, bodily temperature, pain sensations, and so on, we decided to try biofeedback about the user's brainwave patterns themselves. Therefore, the user can learn to consciously control their brainwave activity, automatically leading to great control over counsciousness, focus, and alertness.

How it Works

The Muse headband uses four electrodes on the forehead and ears to detect voltage levels around them, in a technique known as an EEG. This raw data is interpreted by our wrapper for the muse-io application, which uses the OSC protocol to transmit data from the headset to any OSC-capable receiving API.

The program that receives the raw data is written in Python. We spawn a thread that listens for OSC messages and use a dispatcher to handle these events asynchronously. Then, we use a mathematical technique called a fast fourier transform to transform the raw signal from the time domain to the frequency domain-- decomposing the voltage/time graph into a breakdown of amplitude/frequency. From this result, we average those frequencies that are associated with gamma and beta waves, which represent conscious alertness and focus.

To provide user display, the value is displayed in an easy-to-understand graphical interface, which shows a horizontal colored meter that fills up proportional to the user's focus level, with high refresh rate and very low latency.

Challenges

One of the most challenging aspects of this project was the interface from the OSC protocol used by Muse to the Python application that we needed to use to process the data in real-time. Another challenge was creating the graphical output, as we ran into countless problems with mutli-threading and thread locking issues.

What we Learned

We learned how to use the Muse headband to accurately and quickly measure data about the brain as it functions. We learned how to connect with this device's software to extract the raw data in real time, and we learned how to pipe this data into a Python program.

We learned about signal processing with (Fast) Fourier Transforms, and explored the mathematical significance behind this immensely useful (and cool) process. We also learned how to create a live-updating graphical interface in Python, including all of the threading ""gotchas"" that go along with it.

But not only did we learn about data and programming, but building this project was a learning experience in other aspects, as well. Because our team was formed from two partnerships who hadn't worked together before, we learned a lot about how to balance and utilize each team member's strengths in working for the project. As we began working together and sharing fresh ideas and perspectives, our productivity massively increased and we were able to attack problems by using each person's ideas, knowledge, and past experience.

What's next for Focus Friend

Right now, Focus Friend is in the prototype/proof-of-concept stage. Our future plans include:
- Mobile support for Android and iOS
- A monitoring platform for parents and educators to monitor the focus levels and reports of their students
- Possible expansion of the technology to other applications, not just ADHD
",http://www.github.com/vasilescur/FocusFriend,,"Best Education Hack, Best High School Hack, TCS - Best Hardware Hack, 8451 - Make the Customer's Life Easier","python, muse, graphics, processing, osc, numpy",,Duke University,1,860D-1,"Loveland High School, University of Cincinnati","",Alienware Laptop and Muse Headband
Smart Cart,https://revuc-vii.devpost.com/submissions/89756-smart-cart,Submitted (Gallery/Visible),Pending,,03/04/2018 10:30:43,"Inspiration

We wanted to create a Full Stack integrated IoT product that bettered the Consumer Shopping Experience and provides more value to both customer and retailer.

What it does

Hardware unit is attached to a shopping cart and has a touchscreen display and a barcode scanner. Customer scans items and finds out if they're on sale, related items they might want and gets suggested recipes using the product. The store can track popular items/sales/etc, and the server/DB uses machine learning to track what items are being bought with what to continually improve it's recommendations.

How I built it

We have a raspberry pi that simulates the hardware components by taking 12 integer arrays representing UPC barcode values (i.e. 028400091565 = Lay's Classic Potato Chips 1.5 oz bag) since we didn't have a barcode scanner to work with, and it sends the value to a MySQL DB on an AWS cloud server, which identifies the product and checks its relation to other products. The DB uses machine learning in the background to find correlations between product sales to determine what items to recommend. It then sends the product data and related product information back to the Smart Car client device via a web interface with the GUI interface.

Challenges I ran into

We used the Raspberry Pi 3 instead of the Dragonboard 410c because the Dragonboard we checked out was non-functional, and no other working ones were available.

Accomplishments that I'm proud of

Our Full Stack work! We successfully were able to take data in from the Pi, process it in our cloud infrastructure and get the item to show up on the GUI with recommendations.

What I learned

As a team, we all learned new skills for each of our parts of the project. I hadn't ever used Python before, so I had to learn it as I went in order to take input from the keypad connected to the GPIO pins of the Raspberry Pi and push it to the database. Our Database Engineer learned how to create and use an AWS EC2 instance that hosts our database. Our GUI designer learned to use the Flask web service API. Overall we learned a lot about IoT. 

What's next for Smart Cart

Integration with customer loyalty programs (such a Kroger Card, for example) that allows the cart to display a custom shopping list tied to the customer, tailor recommended products to the individual customer based not only on overall trends but their personal purchase history, display coupons connected with the card, etc. 

Potentially, Smart Cart 2.0 could use sensors to detect the products in the cart and could automatically charge a customers account when the leave the store without having to stop at a checkout line, similarly to Amazon Go.
",https://www.shopwithsmartcart.com,,"TCS - Best Hardware Hack, 8451 - Make the Customer's Life Easier, Amazon Web Services - Best Use of AWS, Best Domain Name from Domain.com, Best IoT Hack Using a Qualcomm Device","raspberry-pi, python, html, css, bootstrap, javascript, amazon-web-services, flask, mysql, amazon-ec2, amazon-rds-relational-database-service, machine-learning, jquery, socket.io, keypad, touchscreen",,"University of Louisville, Northern Kentucky University, University of Cincinnati",3,801C-4,"University of Louisville, University of Cincinnati, Northern Kentucky University",AWS,DragonBoard 410C
Nanohack,https://revuc-vii.devpost.com/submissions/89758-nanohack,Submitted (Gallery/Visible),Pending,,03/04/2018 10:34:26,"Inspiration

Nanohack was inspired by the want to make hackathons more prevalent in the industry. If you make a game about it, people will come.

What it does

It captures the idea and theme of a hackathon and presents it in a fun adventure that anyone can enjoy!

How we built it

We used Gamemaker Studio as our game engine. This is what was used to really put everything together. Beepbox and Audacity were used for music and sounds. Aesprite was used for the visual assets.

Challenges we ran into

The timing of everything was honestly our biggest challenge. When making a video game there are many aspects to be considered like programming, music, sounds, sprites and animation. Squeezing all of this into a 24 hour period with only 4 people is very challenging.

Accomplishments that we're proud of

We feel like we've done really well in the time management of our project. There are obviously more things we'd like to do with the game but some sacrifices had to be made to make sure the general idea got across in our short amount of time.

What we learned

I think we learned a lot about time management, project management and just general communication between a small team.

What's next for Nanohack

We have a wait list of ideas for the game that had to be put on hold due to the time constraint of a hackathon. We'd love to implement these ideas and add more levels to make this a more fully featured game that spreads the concept of hackathons far and wide!
",https://github.com/navett52/Nanohack.gmx,,"","gamemaker-studio, aesprite, audacity, beepbox",,"Northern Kentucky University, University of Cincinnati",3,801M-1,"NKU, UC","",""
The Thingamagig,https://revuc-vii.devpost.com/submissions/89759-the-thingamagig,Submitted (Gallery/Visible),Pending,,03/04/2018 10:36:20,"Inspiration

We wanted to make the most useless hardware hack here

What it does

Nothing of use. It plays the Mario theme on a buzzer after the rfid card scanner counter reaches a certain level then resets. The counter data is also passed to a pocketchip that then transmits that data over LoRa.

How we built it

Took as much hardware as we could get our hands on and we threw it together in a machine that does stuff and things. 

Challenges we ran into

We ran out of pins for a hot seconds then we found another uno to use

Accomplishments that we're proud of

We got it too play Mario theme and transmit over RF's

What we learned

How to use RFID technology and SDR technology

What's next for The Thingamagig

Get broken down and returned. 
","",,"Best Education Hack, Best Useless Hack","arduino, sdr, pocketchip, sensors, rfid",,Ohio University - Main Campus,0,860D-2,Ohio University,"",Grove Starter Kit Components
Snapsey,https://revuc-vii.devpost.com/submissions/89766-snapsey,Submitted (Gallery/Visible),Pending,,03/04/2018 10:45:50,"Inspiration

Our Inspiration for Snapsey are the image to text converters which we felt could be extended to provide more functionality.

What it does

Snapsey first prompts the user to take a picture of a food product, then the product name and important nutrition info is given to the user in their native language that they have selected

How we built it

We built Snapsey by integrating Google's Cloud Vision API which converts the picture to the product name, the Nutritionix API which gets the nutrition information for the product, and Google's Translate API which translates the product name and nutrition information together within Android Studio.

Challenges we ran into

One of the main challenges we ran into was working with Gradle which proved to be difficult to manage and get functioning.

Accomplishments that we're proud of

Working from having no experience with Android Studio and Google API's to producing a working
application with them.

What we learned

We learned a lot about Android development as well as using API's

What's next for Snapsey

Some features we could implement into Snapsey in the future include providing pricing information as well as locations where the product can be purchased.
",https://github.com/ctooley21/Snapsey,,"JP Morgan Chase & Co. - Best Hack for Social Good, TCS - Best Hardware Hack, 8451 - Make the Customer's Life Easier","google-vision, google-translate, nutritionix, android-studio, java",,University of Kentucky,2,801M-5,University of Kentucky,"",""
LaserCubes,https://revuc-vii.devpost.com/submissions/89767-lasercubes,Submitted (Gallery/Visible),Pending,,03/04/2018 10:46:59,"Inspiration

The world needed a new way to interact online

What it does

Move around in front of your camera and explore CUBE WORLD

How we built it

We used a face tracking library and three.js to make a 3d virtual world you can play in with your friends

Challenges we ran into

The camera library was poorly documented so we had to hack it up to get something working quickly.
The networking needed to make live online games is tricky, we're doing it for the first time. None of us have programmed in golang before so the decision to use it was a folly, but it worked out well in the end.

Accomplishments that we're proud of

It really works. It works on a cell phone, too.

What we learned

We learned to use three.js to make cool 3d games, how to do client-server interactions, and a quick dive into golang for servers.

What's next for LaserCubes

Replace AJAX with WebSockets so it's faster. 
",https://cubelasers.com,,"","javascript, golang, webgl, vim, aws-lightsail",,"University of Louisville, University of Kentucky",1,801-3,"University of Kentucky, University of Louisville","",""
ApperceptionVR,https://revuc-vii.devpost.com/submissions/89768-apperceptionvr,Submitted (Gallery/Visible),Pending,,03/04/2018 10:47:30,"Inspiration

It would be hard to find someone who hasn't taken a personality test (i.e. Meyers Briggs, DISC assessment, Big Five personality tests, etc.). The problem is that the vast majority of these tests are not evidence-based and lack any predictive power. Also, people are often given these tests under high-stakes (job interview process) and are incentivized to modify their responses to fit into a certain group. To cut through the noise, we wanted to build personality profiles based on initial, gut reactions to simulated situations using VR.

What it does

Jump into a series of curated VR situations aimed at understanding your initial, gut reactions to difficult and ethical situations. While you are immersed, we are measuring a multitude of performance metrics! Our goal is to have around 10 fast-paced experiences that cover topics ranging from stress management, adaptability, creativity, problem solving, and philosophy. Over the past 24 hrs, we built two highly-polished scenarios to test the concept.

Target audience

We imagine that while this tool provides value, the initial investment in the VR setup is high. As a result, our target audience at first would be organizations (businesses, non-profits, military, law enforcement, government).

How we built it

Game engine: Unreal Engine 4

Using C++ scripts attached to Unreal, we were able to record performance metrics during the experience.

3D modeling: 3DS Max

Texturing: Substance Painter

VR headset: HTC Vive

Challenges we ran into

We wanted to collect biofeedback information such as respiratory rate or heart rate in addition to in-game performance metrics. We did a deep dive on heart rate using optical sensors, EKG breakout boards, and even tried to reverse engineer a pulse oximeter. In the end, we ran out of time on integrating biofeedback, but we learned a lot in the process!

Accomplishments that we are proud of


Amount of data that we were able to collect
The insights that we gathered
Examined data from 40 individuals
The amount of work that we were able to complete
Being able to collaboratively work to develop a strong idea
Utilizing VR as a predictive tool for personality tests


What we learned

VR


How to correct for visual anomalies that occur in VR, such as spacial awareness
How to record performance in real-time in Unreal Engine
That VR can be a powerful tool for organizations that goes beyond its initial novelty and hype-factor


Biosensing


That optical pulse sensor is susceptible to motion artifacts
Typical 3 lead EKG sensors do not allow for freedom of motion either


Usability testing


People's reactions vary greatly to physiological and psychological tasks
What measurements would be valuable for feedback in next generations


What's next for ApperceptionVR


Adding biofeedback (heart rate and/or respiratory rate)
Building out a set of validated and curated situations (~10)
Measure interpersonal metrics by enabling multiplayer support
Record verbal reaction to tasks
Watch eye movement
Record extraneous movements of the limbs
Record task speed

","",https://youtu.be/JhiSf9KWqCw,"JP Morgan Chase & Co. - Best Hack for Social Good, TCS - Best Hardware Hack","unreal-engine, c++, htc-vive",,University of Cincinnati,3,801E-1,University of Cincinnati,"",""
Cara,https://revuc-vii.devpost.com/submissions/89770-cara,Submitted (Gallery/Visible),Pending,,03/04/2018 10:50:37,"Inspiration

Passwords are too complicated. Though we'd never compromise our security for financial accounts and other important systems, the fact is it is _ simply too annoying _ to type in a username and password to play video games or submit your math homework. With facial recognition on the rise as a new form of authentication, we felt it was still a rather exclusive feature - often reserved for expensive phones and laptops. We decided to build Cara - the facial recognition platform for everyone.

What it does

Cara is simple - it's a service that offers a drop-in solution for facial authentication. Any app or website can incorporate Cara into their service with ease - all the difficult bits are abstracted away by the robust yet secure technology hiding behind Cara's servers. The idea is to bring the power of this new technology to everyone - from aspiring startups trying to get their products off the ground to freelance developers looking for a way to differentiate themselves from the crowd. In order to prove Cara's widespread applications, we built a series of demos incorporating Cara in different aspects, proving its worth within the family, the education system, and the industry at large.

Family

Dementia and Alzheimer's are terrible to experience - both as the victim and his/her family. Though Cara can't solve major breakthroughs in medical technology, we can help mitigate the memory-related symptoms of these diseases. Cara can be used on AR devices to help patients of dementia or Alzheimer's remember who they're talking to. With the press of a button, Cara will recognize the person in front of you and pull up helpful information about them - such as their name, the last time you've seen them, and where they work. With the power of technology, we can transform the last moments of our elders into memorable experiences rather than painful ones.

Education

""Can anyone tell me who's absent today?"" - a common question repeated across the world every morning in thousands of high school classrooms, Cara can solve this too. Using a simple camera setup in front of every classroom doorway, taking attendance manually becomes a relic of the past. As students filter into the classroom, all they have to do to be marked ""present"" is to tap a screen and wait to be recognized. However, Cara extends beyond simple attendance taking - with a curious mix of psychology and technology, Cara can recognize the emotions permeating a face. In combination with observing facial angles, Cara makes it possible to tell who's paying attention in class - and how they're feeling about it. Teachers can use this feedback to improve their lessons, as well as watch out for under-performing students.

Industry

Lastly, we decided to tackle a problem in the industry - the slowness of employee clock systems. Swiping a time-card or scanning a tag is boring - facial recognition is cool. With Cara, these systems can be easily replaced to be quick and painless. Times are automatically logged between clock-ins and clock-outs, ensuring the integrity of both employees and managers. 

How we built it

At the core of Cara lies Microsoft's Cognitive Services API, providing quick and secure facial recognition routes. Because no images are ever stored on a server, malicious actors that gain access to Cara's data would only encounter useless strings of letters and numbers that represent faces. Aside from Cognitive Services, our back-end is powered by a single Amazon AWS EC2 instance, while a custom-written hand-made API handles interactions between the user and the authentication services. 

Challenges we ran into

One unique issue we encountered was intercommunication between our servers. For some reason, the way the UC network is built disallowed devices from communicating with each other. In order to mitigate this, we decided to move all of our servers to cloud services - dispersing across AWS and Cloud9. On the development side, our seasoned back-end development time found challenges in designing captivating yet concise user interfaces that maintained their look across multiple devices.

Accomplishments that we're proud of

As a group of friends first and foremost, our proudest accomplishment at any hackathon is working together as a team to get closer to our goal - succeeding together, but also failing together. More than the prizes, it's about pushing technology to its limits while continuing to foster a learning environment for everyone.

What's next for Cara

We feel Cara has a bright future - as facial recognition makes its appearance in top-end technologies like the iPhone X, it's only a matter of time before it appears in more and more areas. We plan to be there - ushering in a new age of biometric authentication for small businesses, huge corporations, solo developers, and your grandmother.
","https://github.com/All-Hackathon-Projects/Cara, https://faceinthe.space",,"JP Morgan Chase & Co. - Best Hack for Social Good, Best Education Hack, Best High School Hack, 8451 - Make the Customer's Life Easier, Amazon Web Services - Best Use of AWS, Best Domain Name from Domain.com","microsoft-cognitive-services, amazon-web-services, node.js, express.js, bootstrap, love",,University of Illinois at Urbana-Champaign,3,860D-1,Adlai E. Stevenson High School,"",""
DrumVR,https://revuc-vii.devpost.com/submissions/89772-drumvr,Submitted (Gallery/Visible),Pending,,03/04/2018 10:51:11,"Inspiration

Drumming is fun

What it does

Allows you to drum even if you don't have drums

How I built it

Unreal Engine

Challenges I ran into

Failing on my original project 18 hours into the hackathon

Accomplishments that I'm proud of

Submitting anyway!

What I learned

It's not about what you made but what you learned!

What's next for DrumVR
","",,"","unreal-engine, c++",,University of Kentucky,0,801G-4,University of Kentucky,"",""
RevUC2018,https://revuc-vii.devpost.com/submissions/89776-revuc2018,Submitted (Gallery/Visible),Pending,,03/04/2018 10:55:56,"RevUC2018 
Code Name: Show Me Your Tunes

The goal was to create a twitter bot that could be tweeted at and return a Spotify playlist. In order to build this we used several APIs to get information between the two. The APIs were for Spotify, Twitter, and we used IBM's Watson to pull keywords from the person who tweeted at the bot.

In addition we have also set up a website to loosely track our progress towards our goal.
",https://github.com/ptallo/RevUC2018,,"Best Useless Hack, Best Domain Name from Domain.com",python,,University of Cincinnati,2,801C-1,Univerisity of Cincinnati,"",""
PhotoArcade,https://revuc-vii.devpost.com/submissions/89777-photoarcade,Submitted (Gallery/Visible),Pending,,03/04/2018 10:56:27,"PhotoArcade

Create old school games using your own photos.

Old school arcade games are awesome, but old school arcade games that use your own photos as maps are even better.

Photo arcade seeks to reproduce the feel retro video games with never ending variation in game-play variation provided by your own photo gallery.

By using python and kivy we aim to reach the widest possible audience. PhotoArcade will be able to run on OS X, Windows, Linux, Android, iOS, and Raspberry Pi.
",https://github.com/gyurgyma/PhotoArcade,,Best Useless Hack,"python, kivy",,University of Cincinnati,3,801A-4,University Of Cincinnati,"",""
Beacon-of-Hope,https://revuc-vii.devpost.com/submissions/89781-beacon-of-hope,Submitted (Gallery/Visible),Pending,,03/04/2018 10:58:33,"Inspiration

We were inspired to help those who face natural distasters.

What it does

It is an emergency tracking system designed to help people during natural disasters to better find help and assist others along the way.

How we built it

We created a database using Firebase to store the data from multiple different client apps. Each client app was programmed using Java and XML in android studio. 

Challenges we ran into

Learning how to implement Firebase into android apps; most of the team had to learn to program in Java and XML since they were used to programming in C++. We also had some problems getting the phone to record the GPS coordinates.

Accomplishments that we're proud of

That we over came our challenges to produce a working product, that works just like we planned. We are proud of the many things that we learned: Java, Javascript, how to use android studio, and how to implement Firebase. 

What we learned

Over the course of a very long night we learned how to integrate Firebase into android studio. After we crossed that hurdle we had to learn to work with Json trees in order to use the database we made with Firebase. We did manage to figure out how to import and export from the data base using Json trees and java objects. We also had a very hard time making the backend to maintain the database. We eventally thought of an out-of-the-box solution to solve the problem: we modified a copy of the client app to fill in for the back end of the server.

What's next for Beacon-of-Hope

We also plan to increase the efficiency of the backend of the database to better cycle out old data so the app can run faster and support more people. We also plan to increase the app versatilty making it more applicable and convenient during high stress situations.
",https://github.com/d3bird/Beacon-of-light,,JP Morgan Chase & Co. - Best Hack for Social Good,"java, javascript, xml, google-maps, firebase",,"Ohio State University, Ohio University - Main Campus",3,801-10,Ohio University,"",""
FluidDB,https://revuc-vii.devpost.com/submissions/89784-fluiddb,Submitted (Gallery/Visible),Pending,,03/04/2018 10:59:21,"FluidDB
",https://github.com/drewrip/FluidDB,,"JP Morgan Chase & Co. - Best Hack for Social Good, Fifth Third Bank - Best Fin Tech Solution, Best High School Hack, 8451 - Make the Customer's Life Easier","c++, python, c, json",,"",0,860D-4,Sycamore High School,"",""
Maxland,https://revuc-vii.devpost.com/submissions/89790-maxland,Submitted (Gallery/Visible),Pending,,03/04/2018 11:05:49,"Cincinnati's a big city, let's fill it with homes

Cincinnati currently has a large homeless while property for sale is pricing out would-be buyers.  This speculation harms all citizens of Cincinnati not showing the beauty and the vibrancy that Cincy has.
Let's solve this issue by bringing communities together and getting them housed. 

What it does

Maxland aims to give suggestions on what type of housing to place on the land in order to maximize residential use of the land.   This will help encourage the developmental use of the land and get more people in homes.  It displays the different types of homes with data points on the map, the value it has, and a suggested housing type improvement.

How we built it

Data:  Foreclosure data, home value data, and neighboorhood data came from Cincinnati's Open Data Hub and Hamilton County auditor's office
Data Science: Data Processing and development are done in Python library Pandas
Hardware: Integration with Amazon Alexa under AWS Lambda for serverless cloud architecture
Visualization: Map visualization was done in the Javascript library Leaflet.js, Javascript
Backend: Backend was done in Firebase

Challenges we ran into

Data integrity: Many datapoints lacked full information and were not in easily accessible locations from the auditor's office, and Cincinnati's Data Hub
Javascript coding: Many of us needed to learn or relearn Javascript and how to best code for it. 
Data integration and rendering: We needed a way to integrate asynchronous data and read files into Javascript and render the data to the map which consumed ample time to do so.

Accomplishments that we're proud of

Sourcing information from various government websites
Data processing and extracting data from auditor's website and Cincinnati's Data Hub using Pandas
Learning and improving on javascript skills
Amazon Alexa integration
Group working skills and project scoping

What we learned

Learned completely new languages: Node.js Javascript
Learned completely new technologies: Amazon Alexa, Firebase, Leaflet.js, Amazon AWS, Amazon Lambda, Pandas
Learned data processing and integration

What's next for Maxland

Integrate Amazon Alexa further into the data
Find the size of land and learn more on how to integrate that information into best recommendations
Bug and code improvement
","https://maxland-a79e2.firebaseapp.com/, https://maxlandcincy.com",https://www.youtube.com/watch?v=0AIlpm4srg8&feature=youtu.be,"JP Morgan Chase & Co. - Best Hack for Social Good, Best Education Hack, Best Useless Hack, TCS - Best Hardware Hack, Amazon Web Services - Best Use of AWS, Best Domain Name from Domain.com","javascript, firebase, amazon-web-services, amazon-alexa, pandas, python, leaflet.js",,"University of Cincinnati, University of Indianapolis, Ohio State University",3,860D-5,"University of Cincinnati, University of Indianapolis, The Ohio State University","",""
BinarySolVR,https://revuc-vii.devpost.com/submissions/89791-binarysolvr,Submitted (Gallery/Visible),Pending,,03/04/2018 11:06:11,"Inspiration : We wanted to make a game that also was able to be used by teachers for testing students.

What it does : It is a game that gives you a decimal number and you then have to change the switches in game to make it into a binary number. There are a total of 5 levels each with randomly generated numbers. Once the final level is beaten the win screen comes up.

How I built it : We built it using Unity & Visual Studio for the coding and logic. And for the trophy at the end and the room in the game we used Blender to create the objects.

Challenges I ran into : No one in our group had used Unity or Blender before and only one of us knew some C# which Unity uses as its coding language.

Accomplishments that I'm proud of : Getting the game working in 24 hours after not knowing how to do anything in unity or blender before we started the project. Getting it working in VR in a very short time.

What I learned : We learned how to use Unity and how to write logic in Unity using C# in Visual Studio.

What's next for BinarySolVR : Give it to teachers so they can have their students work with it and possibly test them using the game.
","",,"Best Education Hack, Best Domain Name from Domain.com","unity, blender, visual-studio",,University of Cincinnati,2,860B-7,University Of Cincinnati,Domain.com,Alienware Laptop and Oculus Rift
DashWall,https://revuc-vii.devpost.com/submissions/89797-dashwall,Submitted (Gallery/Visible),Pending,,03/04/2018 11:16:41,"IWishIWasACyb.org

Inspiration

We've attended hackathons before, but had never used microcontrollers before. We wanted to learn how to use these tools while creating something that we ourselves would use.

What it does

DashWall is a wall display with home diagnostics at-a-glance. It displays the time, and uses its sensors to determine the indoor temperature, sump pump water levels, and changes its brightness depending on ambient light levels.

How we built it

We built DashWall using Windows 10 IoT on a Qualcomm DragonBoard 410c, using a Microchip as a makeshift ADC to interface with our sensors.

Challenges we ran into

We ran into an issue with transferring data from the Microchip to the DragonBoard that remained unsolved for several hours, eventually being solved by the addition of a ground wire between the microcontrollers. This was definitely a lesson we won't forget when using microcontrollers in the future!

Accomplishments that we're proud of

We finished what we outlined in our MVP! Time display and sensor-driven temperature and adaptive brightness!

What we learned

DON'T FORGET THE GROUND.

What's next for DashWall

We're looking forward to integrating more sensors and helpful APIs for things like displaying todo lists and weather forecasts.
","",,"TCS - Best Hardware Hack, Best Domain Name from Domain.com, Best IoT Hack Using a Qualcomm Device","qualcomm, windows-10-iot",,University of Cincinnati,1,801C-5,University of Cincinnati,"","DragonBoard 410C, Grove Starter Kit Components, and Intel Starter Kit Components"
Simply Useless Simple Uses,https://revuc-vii.devpost.com/submissions/89798-simply-useless-simple-uses,Submitted (Gallery/Visible),Pending,,03/04/2018 11:17:05,"Inspiration

We're all three freshmen right now with a growing yet limited knowledge of coding. We wanted to branch out a little bit at RevolutionUC, so we decided that we wanted to take advantage of the 24 hours and learn HTML and website design.

What it does

Our program/website runs a variety of mini-programs that run amusing functions that do absolutely nothing.

How we built it

We started off writing our functions in C++, a language that we are all familiar with, then we researched how we can translate that into JavaScript.

Challenges we ran into

Going into this, none of us knew anything about how to design a website. We struggled with doing simple things and it felt like we were getting hurdle after hurdle thrown at us.

Accomplishments that we're proud of

We're very proud of what we've accomplished here. We have learned the basics of two different new languages that can be used in nearly any future profession.

What we learned

We've learned how to do basics in HTML formatting, JavaScript, and how to style using CSS
",http://simplyuselesssimpleuses.com.s3-website.us-east-2.amazonaws.com/,,"Best Useless Hack, Amazon Web Services - Best Use of AWS, Best Domain Name from Domain.com","html5, javascript, css",,Ohio University - Main Campus,1,801M-8,Ohio University,AWS and Domain.com,""
Mind The Gap,https://revuc-vii.devpost.com/submissions/89800-mind-the-gap,Submitted (Gallery/Visible),Pending,,03/04/2018 11:23:29,"Inspiration

We were inspired to create an app that would increase mindfulness and positivity. Oftentimes people get stressed and become negative through the busyness of life and the portrayal of the world through media. We wanted to build an app that would allow others to journal about what good happened to them today and what good they did that day. Users would then be able to view what others have written anonymously. 

What it does

It is an app that is connected to a database. Currently, all it does is allow the user to type in what they would like to write and then swipe to a page that would have what others have written. 

How we built it

We used React-Native to build this app. 

Challenges we ran into

Integrating with a database was a pain and took much of our time. The error messages presented on the screen were also not very informative as to what the problem was. 

Accomplishments that we're proud of

While we don't have much, we did learn how to create a basic application in React. This was overall a great ( and frustrating ;) ) learning experience. 

What's next for Mind The Gap

To have the database also syncs with a remote database and be able to have multiple users be able to see updates in real time. We would also like to work on the interface and have the design be more user friendly. 
",https://github.com/johnsonwe/mindthegap.git,,Best Useless Hack,"react-native, android",,Berea College,2,860B-2,Berea College,"",""
Satellite Chasers,https://revuc-vii.devpost.com/submissions/89803-satellite-chasers,Submitted (Gallery/Visible),Pending,,03/04/2018 11:24:04,"Inspiration

Each member of Satellite Chasers is a member of the UC CubeCats (http://uccubecats.org/), an undergraduate student organization dedicated to the education of members through the construction of Cube Satellites, and High Altitude Balloons. We wanted to learn more about antenna design, and construction and how satellite communication works. This will aid us in designing a ground station to communicate with our satellite Project Leopard that will be launched into Orbit within the next few years.

What it does

Our Omni-directional double cross antenna receives signals on the VHF frequency band at around 137 MHz. The antenna is constructed of steel cable, copper fittings, and COAX cable all made for under 35 dollars. 

How we built it

The antenna was constructed by mounting quarter wavelength steel dipoles on a wooden support structure and then connecting them to 4 coaxial cables that were then connected to a computer via SDR#.

Challenges we ran into

The largest challenge that the group overcame was adjusting the sampling rate of the system to that of each individual satellite that flew over. Furthermore the cross connection of the quarter wavelength steel dipole antennas and splitting of the coax cables was a challenge. There were no wire strippers available to strip, and disassemble 3/8"" coax cable so a new process had to be created to strip and separate the core and conductive shielding or the cable. 

Accomplishments that we're proud of

As a team we are proud that we were able to sample images from a NOAA weather satellite for under 35 dollars. The team worked extremely well together and was able to prototype and build the antenna within 12 hours of the start of the hackathon.

What we learned


How to calculate and design an antenna for proper gain of a desired frequency
How to use SDR# to trans-code images from an analog signal
How to decode a wav audio signal from a satellite into a static image


What's next for Satellite Chasers


Automation of a control system to sample satellites without a human user to initialize satellite contact (beacon signal for connection).
Apply the knowledge learned from the project towards the completion of the UC CubeCats ground station that will be used to communicate with satellites in Low Earth Orbit (LEO) over VHF and UHF frequency bands.
Design an antenna for use at higher frequencies and possibly communicate with Geo-Stationary Satellites

","",https://www.youtube.com/watch?v=55zyem2PHWg&feature=youtu.be,TCS - Best Hardware Hack,"hardware, wxtoimg, sdr#",,University of Cincinnati,3,801-7,University of Cincinnati,"",""
LowDiskReader,https://revuc-vii.devpost.com/submissions/89807-lowdiskreader,Submitted (Gallery/Visible),Pending,,03/04/2018 11:30:54,"Inspiration

I wanted to make software which does not have dependencies and the code i have is all the code.

What it does

It contains methods for printing text numbers and errors codes from disk reads.

How I built it

I used nasm to build it.

Challenges I ran into

The code ran into some errors that are unknown.

Accomplishments that I'm proud of

It runs pretty good

What I learned

I learning how to build a program on top on the x86 architecture independent from any libraries.

What's next for LowDiskReader

I want to rework the disk reading to work so i can work with more memory instead of working with the initial 512 bytes of memory. Then make a basic DOS OS with all basic library functions an OS has.
",https://github.com/ryoung9550/ucRevProject/blob/master/bootstrap.asm,,"",assembly,,University of Cincinnati,0,801C-2,University of Cincinnati,"",""
Heart Disease Risk Assessment,https://revuc-vii.devpost.com/submissions/89808-heart-disease-risk-assessment,Submitted (Gallery/Visible),Pending,,03/04/2018 11:31:04,"Inspiration

We are interested in machine learning and would like to pursue a career in ML or data science. Because of this, we decided to try implementing some sort of prediction model for a disease which is heavily influenced by certain lifestyle risk factors and could help early intervention in hospitals. We thought heart disease would be perfect for this purpose because it is the number one cause of death in the world and has many preventable factors.

What it does

It uses 270 samples (we could also incorporate an additional 303 which we have been using for testing) to train a model for heart disease prediction based on 13 different factors recorded on hospital admission. It provides an interface for health care providers to enter in data about the patient and obtain a suggestion of whether or not to consider screening/intervention.

How we built it

We used the markov learning network package _ tuffy _ to structure the first order logic of our world and the rules within it. We then tested on our expected weights, and got an accuracy of 67%. We used tuffy to reevaluate our weights and tested again to get an accuracy of 89% on the other 303 samples set aside for testing (we believe however that there may be significant crossover with the 270 sample dataset). Using a 5 k-fold cross-validation we obtained 80.7% accuracy. Finally we tried out a learning ensemble with 100 instances of randomly aggregated MLN models to obtain 82.6%. This was only slightly better than the cross-validation and took many hours to train, so we believe that using a learning ensemble with this problem is not enough gain for the cost. After doing these analyses of our data, we created a front-end to our functionality to allow a user to input health data and assess whether or not the individual is at risk and should take precautions/screening.

Challenges we ran into

It took us a lot of time to accurately model the data into a set of rules and weights and we needed to research and learn a lot about heart disease. In addition, we had to ensure the correctness of the dataset and make sure we fully understood each column. The learning ensemble was also a bit difficult to implement due to scalability reasons, which lead us to shift focus because it seemed impractical.
We also were unable to implement blood pressure because the data was possibly incorrect and negatively affected the accuracy. This is disappointing because blood pressure seems like it could be a very useful piece of information to predict heart disease.

Accomplishments that we're proud of

We were very pleased with the accuracy we were able to obtain. Over 80% was great to us and we believe it could possibly even be improved with more analysis.

What we learned

We learned about Markov Logic Networks, first order logic and learning ensembles, as well as the risks related to heart disease. We also each had different skill-sets coming in, so it was very helpful to learn off of each other instead of learning these things by the books.

What's next for Heart Disease Risk Assessment

The accuracy could possibly be improved by assessing the importance of each feature/predictor. We could also improve the running time by storing the models instead of generating them on runtime. We generate the model because the user can omit certain data in their query, in which case the model needs to be generated differently. We can get around this by storing every possible model and using that data instead of generating, because memory is relatively cheap.
","",,JP Morgan Chase & Co. - Best Hack for Social Good,"tuffy, python, bash",,Ohio University - Main Campus,1,860D-2,Ohio University,"",""
eyeRoom,https://revuc-vii.devpost.com/submissions/89809-eyeroom,Submitted (Gallery/Visible),Pending,,03/04/2018 11:33:02,"Inspiration

We're a part of our school's local ACM chapter. We have a club room that people hang out in during the day and into the night. It serves as a hangout spot, a study spot, and a club social outreach center. There's a problem when you have a large organization and a small room, though. Sometimes people come in wanting to study and find it jam packed full of people. Other times people come into the room expecting to hang out with their friends only to find the room empty! Sometimes members are only looking for specific other members while trying to avoid particular people. 

We decided an automated solution to this would save us some hassle.

What it does

Using opencv, running on a raspberry pi with a webcam, we capture images of a room and determine the number of individuals in the room. The image of the room and the meta data is then pushed to a firebase server. A telegram bot can be used to access the server and report to users the status of the room.

How we built it


opencv + raspberry pi w/ camera for image processing of the room.
firebase database for storage of data
python telegram bot for user interface


python-telegram-bot
pyerbase

dynamic webpage for user interface


html5
css
javascript
firebase



Challenges we ran into


Amazon lambda and Amazon Alexa skills turned out taking a longer time than expected to get working.
Compile time and network conditions slowed progress.


Accomplishments that we're proud of


We stack cups really well.
A health amount of code was finished within the first 12 hours, compile times delayed the remaining portions.


What we learned


Opportunity to work with new languages and packages.


What's next for eyeRoom


Integrate Alexa skills as another form of user interface.

","https://github.com/therobotcarlson/eyeRoom, https://github.com/therobotcarlson/eyeRoom/tree/gh-pages",,"Best Useless Hack, TCS - Best Hardware Hack, Amazon Web Services - Best Use of AWS","python, opencv, raspberry-pi, telegram, amazon-web-services, firebase, node.js",,University of Kentucky,3,801G-5,University of Kentucky,AWS,Amazon Echo
Electronic Music Maker,https://revuc-vii.devpost.com/submissions/89812-electronic-music-maker,Submitted (Gallery/Visible),Pending,,03/04/2018 11:36:40,"Electronic Music Maker

What it does

The Electronic Music Maker can make electronic music sounds that are used to create electronic music.  The interface for this is turning the knobs and buttons on the board.

How it works

There is an Arduino that is used to generate sounds and drive a speaker using PCM.  The sounds are generated by turning the knobs on the board. 

What the knobs do (from left to right)

1) Control frequency
2) Control delay in between notes
3) Control length of notes
4) Control range of frequencies.
",https://github.com/Tyler-Hilbert/Music-Maker,https://vimeo.com/258503035,"Best Useless Hack, TCS - Best Hardware Hack",arduino,,University of Cincinnati,0,801B-2,University of Cincinnati,"",""
Some Kind of Clock,https://revuc-vii.devpost.com/submissions/89813-some-kind-of-clock,Submitted (Gallery/Visible),Pending,,03/04/2018 11:38:18,"Inspiration

My group and I thought it would be fun to make an alarm clock that does more harm than good to the user

What it does

Not much right now, it's mostly just a clock

How I built it

Originally with C++ and a time library, but now with the Qt Framework

Challenges I ran into

Group issues, and obtaining the necessary building materials

Accomplishments that I'm proud of

Fixed a bug with Qt that prevented me from using it

What I learned

Pre-Planning a project with a group would've been a much better idea. I learned a lot about the groundwork of app/software development with a GUI

What's next for A Form of Clock

Probably the recycling bin, than learning more about the Framework that built it.
","",,"","c++, qt",,Ohio University - Main Campus,0,860B-4,Ohio University,"",""
Vitamin-Cynth,https://revuc-vii.devpost.com/submissions/89819-vitamin-cynth,Submitted (Gallery/Visible),Pending,,03/04/2018 11:50:06,"Inspiration

What if you could play music with fruit?

What it does

It allows you to play music with a fruit-based keyboard.

How we built it

We built it with an Arduino, a capacitive touch board, and fruit.

Challenges we ran into

Real-time audio can be a challenge, especially using embedded boards.

Accomplishments that we're proud of

You can play music by touching fruit.

What we learned

Capcitive touch, real time audio, tone generation.

What's next for Vitamin-Cynth

Generate sine and sawtooth waves, in addition to square waves. Allow user to modulate the pitch in real time. Change octaves up or down.
","",,Best Useless Hack,"arduino, fruit",,University of Cincinnati,0,801A-1,University of Cincinnati,"",""
Delicious Dishes -860B-5,https://revuc-vii.devpost.com/submissions/89820-delicious-dishes-860b-5,Submitted (Gallery/Visible),Pending,,03/04/2018 11:50:25,"Inspiration

What it does

How we built it

Challenges we ran into

Accomplishments that we're proud of

What we learned

What's next for Delicious Dishes
",http://www.deliciousdishesapp.com,,"8451 - Make the Customer's Life Easier, Best Domain Name from Domain.com","android-studio, html",,University of Cincinnati,3,860B-5,University of Cincinnati,"",""
while(i<= 6Â°) { friend = friendOfFriend },https://revuc-vii.devpost.com/submissions/89855-while-i-6-friend-friendoffriend,Submitted (Gallery/Visible),Pending,,03/04/2018 12:03:19,"Inspiration

You meet a stranger on street but you seem to know them from somewhere. Won't it be awkward if you don't remember their name? - This AR application will help you avoid this situation

You are walking down a street and feel you are alone and in a foreign land, but really are you? There are people related to you by some mutual connections everywhere.

link

What it does

We use Samsung's GearVR to access the augmented reality to identify in real-time how the person is related to you. It also shows the shortest path of your connection (example : friend of a mutual friend). It scans the environment and calls the machine learning API for facial recognition. Which maps the person to the database collected from popular social networks like LinkedIn, Instagram, Facebook to say how they are related to you.

How we built it

Use used the gearvr API's to write an android code which captures the images and calls the backend java spring code for image conversion. The java spring backend internally calls the python machine learning API's to recognizes the faces and query a mongodb database to identify which user is this and how its related to the user who submitted the query.
We are currently using BFS for traversing the nodes in the database to identify the path between two users

Challenges we ran into

One of the major challenge was the exploration of uncharted territories in GearVR api due to lack of documentation and also machine learning API for facial recognition. Another issue we faced was conversion of a steam of bytes from android to a image suitable for recognition. 
Implementing the DLIB cross platform software library for image processing and facial recognition.

Accomplishments that we're proud of

Implementing GearVR API.
Machine Learning API for facial recognition.
Constructing a middleware in java spring which communicated between the AR and machine learning API.
Querying MongoDB to retrieve appropriate results

What we learned

The exploration of GearVR API's and choosing the right gear for implementing the augmented reality.
The machine learning concepts of how images as a byte stream can be used to recognize facial features.
Optimization of queries in MongoDB.
How to collaborate with team of different technology stack and integrate our work.

What's next for while(i<= 6Â°) { friend = friendOfFriend }

The concept can be used for natural disaster recovery where the people can find their relatives and make sure they are okay in case of emergencies. It brings solace and peace of mind.
This concept can also be used to find overcome and prevent criminal activities by police authorities using it to recognize threats.
Security surveillance in case of crowded places. 
","https://github.com/abhimanyuchadha/VR_People_Connection, https://github.com/srinivasrk/AndroidVRApp/tree/master/template/GVRFApplication-MLH",,"JP Morgan Chase & Co. - Best Hack for Social Good, Best Education Hack, TCS - Best Hardware Hack, Amazon Web Services - Best Use of AWS","python, augmented-reality, android, java, spring, oculus-gear-vr, amazon-web-services, neural-networks, face-recognition, mongodb",,"University of Cincinnati, Georgia Institute of Technology - Main Campus",3,801G-2,University of Cincinnati,AWS,Samsung Gear VR
Willow,https://revuc-vii.devpost.com/submissions/89859-willow,Submitted (Gallery/Visible),Pending,,03/04/2018 12:07:13,"Willow

UC Hackathon

Description

Do you ever forget about after-school events and activities? Do you consistently get frustrated with the lack of organization for your events?

Enter Willow: a program that connects all of your after-school activities in a central location.

This program gives you an overview of all of the after-school activities you have and when they occur. They allow clubs and their leaders to send messages and reminders to members. A calendar overview allows people to see what events they have in the future.

The life of a student is already stressed from an excess of activities and tests. This program would relieve some of the uncertainty in a student's everyday life.

The app is also streamlined from a data perspective. We utilized the Google Sheets API so that club data would be stored in easily changeable spreadsheets. Club leaders can also use Google Forms to input data, and we handle the processing.

Languages/Libraries/APIs

Java, JavaFX, Jfeonix, Google Sheets API

Challenges

We had a near infinite amount of challenges with our project. We all have really never used GitHub at the same time before, leading to a countless amount of merge errors and lost work. We also learned JavaFX, which took up the largest amount of our time. Writing complex GUIs caused tons of errors and wasted FXML files as we had to restart several times. We also realized that half of us were on Java 1-9, not Java 1-8, thus causing errors as methods didn't exist. This wasted more time as the download speeds were not optimal. Finally, the Google Sheets API was harder to implement than we anticipated. While guides did exist, these did not work and we had to write a few custom classes to interpret, read, and parse the data correctly.
",https://github.com/MJVL/Willow,,"Best Education Hack, Best High School Hack","java, google, google-spreadsheets",,"",1,860D-7,William Mason High School,"",""
BudgetBuddy,https://revuc-vii.devpost.com/submissions/89866-budgetbuddy,Submitted (Gallery/Visible),Pending,,03/04/2018 12:12:14,"Inspiration

So the inspiration of the this app was from a cumulation of group interests. Two of us came in the desire to code while the our other group member came from a desire for financial tracking, while cumulated perfectly into a budget tracking app.

What it does

Our app mirrors of a mobile pay application, except for the fact that it tracks those transactions and leaves the user to review them. It the takes these reviews into an account to better suggest a budget for the next month, with negativity reviewed transactions getting partially dropped from the budget.

How I built it

The application was built in XCode, using the swift coding language, accomplished through Youtube, the mentors, and group problem solving among our members.

Challenges I ran into

The main challenges were consistently managing the new syntax, more specifically implementing a sliding user-interface (which was never accomplished).

Accomplishments that I'm proud of

Developing an app in an unknown language within such a sort period of time, along with a overcoming many bumps along the way. 

What I learned

Swift.  All members were forced to learn the language from scratch, which offered a great achievement beyond building the app as everyone gained greater knowledge of a new language.

What's next for BudgetBuddy

Whats next would be achieving a seamless feel in between banking, budgeting, and living as well as creating a system that would allow its users to put in savings or to charity on top of each purchase, with an end goal of being offered along with a major banking company.
",https://github.com/jakeocinco/BudgetBuddy-REVUC,,"JP Morgan Chase & Co. - Best Hack for Social Good, Fifth Third Bank - Best Fin Tech Solution, 8451 - Make the Customer's Life Easier","swift, cocoapods, github, youtube",,University of Cincinnati,1,801-13,"University of Cincinnati, Ohio University","",""
Smart-Calendar,https://revuc-vii.devpost.com/submissions/89876-smart-calendar,Submitted (Gallery/Visible),Pending,,03/04/2018 12:20:55,"Inspiration

For this hackathon we've decided to create a personalized wall calendar that interacts with you personalized google drive by accessing your data and photos. We decided to go with this app to help keep track of family appointments with personalized pictures for everyone to  enjoy

What it does

This calendar will update with your phone calendar to your wall calendar so you and your family can keep track of each others meetings and appointments!

How we built it

We built this application using python, google api console, and google oauth authentication protocols. We uploaded all of our code with github, and integrated it with our snapdragon board.

Challenges we ran into

The biggest challenges we ran into were troubles connecting the snapdragon board to the internet to get our calendar files, also populating a grid with dates in the appropriate spaces alongside populating each box with the appointment and dates in a well-spaced manner.

Accomplishments that we're proud of

We are very proud of creating a functional application that updates in real time with your google drive calendar within the day time limits.

What we learned

We learned how to get information for a Google drive api, learned how to create a calendar gird in python and populate with parsed inputs, we also learned how to integrate with the snapdragon board.

What's next for Smart-Calendar

we would like to have an easily switch-able calendar and to add events directly from the wall calendar to phone.
",https://github.uc.edu/beckerau/calander,,"JP Morgan Chase & Co. - Best Hack for Social Good, TCS - Best Hardware Hack","dragonboard, snap-dragon, python, google-drive-api, google, oatuh2, anaconda, google-calendar, google-calendar-api",,University of Cincinnati,2,801A-3,university of cincinnati,"",DragonBoard 410C
Alexa secretary,https://revuc-vii.devpost.com/submissions/89884-alexa-secretary,Submitted (Gallery/Visible),Pending,,03/04/2018 12:24:28,"Inspiration

What it does

How we built it

Challenges we ran into

Working with 3 different languages was difficult. Just trying to convert the google doc to a useable database in python was hard, but getting the hang of Alexa took the entire 24 hours. 

Accomplishments that we're proud of

Getting an actual skill to work with Alexa. Even though it's slightly handicapped by the modules I used to work with Alexa it still works.

What we learned

Started out rough in python with no experience in JSON or ever touch amazon web services or the Amazon Alexa. Now I have learned how painful it can be working with Alexa, trying to get here to communicate the way you want her to. However, I have learned a lot about Alexa and I am interested in finding better ways to improve what I have started.

What's next for Alexa secretary

More integration with the app and hopefully being able to send actually contacts to your phone
","",,"Fifth Third Bank - Best Fin Tech Solution, Best Useless Hack, 8451 - Make the Customer's Life Easier, Amazon Web Services - Best Use of AWS","python, amazon-web-services, alexa, json",,University of Cincinnati,1,801-9,University Of Cincinnati,AWS,Amazon Echo
Smart Relief ,https://revuc-vii.devpost.com/submissions/89896-smart-relief,Submitted (Pending),Pending,,03/04/2018 12:28:47,"Inspiration

Interest in using blockchain technology to make a difference.

What it does

Helps maintain transparency for charitable organizations when distributing funds. 

How we built it

We wrote an example of a smart contract to facilitate donations and make donations transparent between organizations and people in need. We wrote the smart contract in solidity and made a simulation using javascript and jquery. We used html and css to create a web page to showcase our ideas. 

Challenges we ran into

Learning and understanding the ideas and technology behind blockchain, and how it could be used to solve this specific problem. 

Accomplishments that we're proud of

We are proud to create a project that holds charities accountable, and that maximizes the percentage of donations to people in need. 

What we learned

We learned more about blockchain technology, and its impact on technology outside of cryptocurrency. We also learned how to create a smart contract using solidity, and simulate it using javascript and jquery. Finally, we learned how to use html and css to make a website which displays our ideas and technology. 

What's next for Smart Relief

Our next step for Smart Relief is to connect our local smart contracts to the Ethereum network. 
","",,JP Morgan Chase & Co. - Best Hack for Social Good,"solidity, javascript, html, css, jquery",,University of Michigan - Ann Arbor,3,801-8,University of Michigan,"",""
autoLift,https://revuc-vii.devpost.com/submissions/89910-autolift,Submitted (Gallery/Visible),Pending,,03/04/2018 12:40:14,"Inspiration

Our team is composed of three student-athletes. Two of us are Olympic weightlifters  and former national champions who compete in Team USA sanctioned events, and the other is a D1 athlete at the University of Minnesota -- Twin Cities. Therefore, we spend a great deal of time planning/recording our workouts by writing in a journal. After a brainstorm session and a desire to use hardware, we thought it would be cool of there was an app that could automatically record our lifts. This gave rise to our app idea: autoLift.

What it does

The user wears a Myo armband which connects to a phone via Bluetooth. By clenching a fist or grabbing a barbell / dumbbell, one would initialize the rep counting mode. Once the grip is released, the app returns the number of reps completed in the set.

How we built it

We used an Myo armband to send acceleration, orientation, and gyroscope data to our Java program. We wrote a physics-guided program to classify each rep.

Challenges we ran into

We spent most of our time with the rep counting methods and understanding how the Myo armband works. The â€œonAccellerometerDataâ€ function did not output the data we anticipated, so we rushed to understand the other gyroscope and orientation data to see what it is that we exactly need for our algorithm.

Furthermore, we received a lot of false positives from the onPose method from the Myo SDK. This made it tough to record when a set begins and ends.

Accomplishments that we're proud of

Learning was a big part of our goal. This was the first hackathon for 2/3 of our team, and we all encountered new concepts/skills which made for a great learning experience.

But most of all, we're proud of overcoming our challenge of classifying data from our Myo armband while making everyone on our team a key contributor to our project, regardless of how much CS experience. One of us is a physics major who came up with an algorithm to use acceleration to classify a rep and communicated his idea with pseudo code. Another one of us with experience in IT was a significant contributor to troubleshooting efforts when connecting the Myo armband and app. And our last member who wrote the most code was the only one who had experience in Android studio which became our medium for developing our app.

What we learned

We learned how to create an Android application using Android Studio and incorporate hardware into code. Our team is composed of three students with diverse academic backgrounds, one student being a non-CS major or minor. We all learned things both from each other and from fast-paced Googling.

What's next for autoLift

We have a whole UI sketched and planned out on paper but are still in the works of completing it. The end goal for our app's ""workout mode"" is to classify and record the movement type, weight, and reps of each set using data sent from the Myo armband. Each set would be outputted to a text file in a row, much like how one would write in their workout journal. Ideally, we'd like to use machine learning to classify each lifting movement without the user doing anything other than perform the movement (we're currently setting the movement explicitly). Each set will be saved as a row of text in a workout log that can be viewed during and after the workout.
",https://github.com/NathanOelke/RevolutionUC-2018,,TCS - Best Hardware Hack,"java, myo, android-studio",,Bowdoin College,1,801-14,"Bowdoin College, University of Minnesota -- Twin Cities","",Myo Armband
Pryoritize,https://revuc-vii.devpost.com/submissions/89922-pryoritize,Submitted (Gallery/Visible),Pending,,03/04/2018 12:58:23,"Inspiration

We are bad at making decisions.

What it does

Makes the decisions for us.

How we built it

We made a website and a proof of concept phone app to how how the app functions and how it will be useful in day to day life. 

Challenges we ran into

We aren't very experienced with android or php. So the whole project was a challenge.

Accomplishments that we're proud of

The app doesn't crash.

What we learned

How to use php with MySQL

What's next for Pryoritize

Fully finalized app and a more robust online version. 
","",,"","php, css, html5, javascript, java, xml, android-studio",,Wright State University,3,801B-4,Wright State,"",""
Relational Image Map,https://revuc-vii.devpost.com/submissions/89932-relational-image-map,Submitted (Gallery/Visible),Pending,,03/04/2018 13:08:19,"Inspiration

I wanted to learn frontend development (although it quickly grew into a lesson in full-stack development) so I decided to create I started to learn Angular, but I learn best when I'm actually working towards a goal so this was one of the ideas that I came up with when working towards that goal.

What it does

Using a user search query and options, it plots images onto an OpenLayers map. As of right now, it uses spare mock data and doesn't even display the images on the map primarily because OpenLayers is annoying (more on that later).

How I built it

Angular5 in the frontend using OpenLayers to provide a map API. In theory, the user would then select search options and input a search query which is then be sent to a search service that processes the search through the Facebook and Twitter APIs to return links to images. Those links are then passed to another service that extracts the necessary EXIF data (latitude longitude, and timecode) from the image and sends stores that data along with a UID to the in a Firestore collection. The frontend is then notified with the image UIDs and which then fetches the images using the UIDs and plots them back onto the map.

Challenges I ran into

Interaction between frontend and backend services is a lot more complicated than I thought especially when they exist cross-domain. Also AppEngine takes quite literally (I timed it) about 10 minutes to deploy a new version of the Image Service each time I wanted to change it. OpenLayers is incredibly difficult to work with and it doesn't help that the documentation is incomplete, to put it nicely.

Accomplishments that I'm proud of

Getting the UI to look halfway decent but it still needs a lot of work as does the entire frontend.

What I learned

That I need to learn a lot more about the interaction between frontend and backend services. What I did learn about this interaction will help a lot in the future. Above all however, I learned API selection should be carefully thought out. As stated multiple times now, OpenLayers is overtly complicated. It's the D3 of map APIs.

What's next for Relational Image Map

I plan to see the project through to completion. I would like to refactor the frontend to use @ngrx/store so it's a bit easier to debug and implement lazy loading especially for the map module so it's not so awfully slow loading. Eventually the project might switch to Google Maps for the maps API as OpenLayers may be more trouble than its worth. It may also switch off Firebase and AppEngine onto a fully-managed Kubernetes cluster in GKE or ECS. I would like to eventually implement object recognition so that when the images are processed, they are also tagged with whatever is in the image for future reference.
",https://relational-image-map-dev.firebaseapp.com/,,Best Useless Hack,"angular.js, golang, python, firebase",,University of Cincinnati,0,801-11,University of Cincinnati,"",""
GunSafe,https://revuc-vii.devpost.com/submissions/89937-gunsafe,Submitted (Gallery/Visible),Pending,,03/04/2018 13:16:13,"Inspiration

In the wake of the tragic shootings in schools, concerts, and other venues in recent months, the GunSafe team felt moved to act. At the very least, our goal was to lay the groundwork for further development of a cost-effective approach to enhancing the detection of firearms in real-time so that further tragedies such as in Orlando and Las Vegas can be prevented before they occur.

What it does

It uses a system of wifi beacons (RFID or Bluetooth beacons in a real-world implementation) that would be placed around a safe zone that can detect when a certain device (""the chip"") enters the network's range. When this chip, which would be attached to a firearm in such a way that removal or tampering is impossible, this system sends an alert to the owners of the venue or location (think school principal, resource officer/security personnel). This alert not only notifies, but also provides real-time data about the incident. (Location of the firearm, the firearm's serial number, and the time and date.)

How we built it

We used a Raspberry Pi that hosts a JSON file on a server to act as a stand-in of the chip. The beacon then scans the network for any device whose hostname fits a pattern, and then sends an alert via. a JSON API to the central alert system and database. After that, the alert is displayed on the screen with the current real-time data.

Challenges we ran into

Integrating a complex API endpoint into the workflow of the app without time to write proper tests that fully cover functionality proves to be quite difficult.

Accomplishments that we're proud of

Getting the system working with the basic functionality that allows for the current team or any future contributors to quickly advance the development of this system.

What we learned

Integrating a JSON API and scanning a network for hostname.

What's next for GunSafe

The current structure of the application is only for a proof-of-concept of the web-based backend. In a future, real-world implementation, the wifi-based beacon will be replaced with some form of passive signal, most likely an RFID beacon that can trigger a chip that would be hypothetically required as part of future gun sales. In this future implementation however, the web-based backend could remain the same with only the detection mechanism needing to be modified.
","https://github.com/lawhorkl/gunsafe_main, https://github.com/lawhorkl/gunsafe_beacon",,JP Morgan Chase & Co. - Best Hack for Social Good,"ruby, ruby-on-rails, html5, css3, api, json",,University of Cincinnati,0,801A-5,University of Cincinnati,"",""
Budget for a Cause,https://revuc-vii.devpost.com/submissions/89939-budget-for-a-cause,Submitted (Gallery/Visible),Pending,,03/04/2018 13:24:36,"Inspiration

We believe that a majority of people want to do good in the world. At the same time a lot of people believe that they cannot afford to give anything. This is why we created Budget For a Cause, the application that allows you to take control of your finances so you can give more effectively.

What it does

Budget For a Cause is a budgeting application that gives you the power to give more effectively. You decide how much you want to give every month, and we give you the knowledge to do so. You can even set up automatic payments to your selection of charities. Every bit counts so we will take whatever you can afford and split it among all of your selected charities.

How we built it

We use Node.js to host a server-rendered web-application using Pug and Sass. We also use AWS to host an instance of a MySQL database for transactions.

Challenges we ran into

We attempted to use the Plaid API which allows developers to scrape bank transactions and categorize your spending. We also planned to simulate a transaction in real-time using the Vantiv e-Commerce API. We got the API working outside of the project but ran out of time to actually implement the scenario in the web page.

Accomplishments that we're proud of

We believe that Budget For a Cause could be a lot more than just a hackathon project, we hope to take this idea farther and make a huge impact on society.

What we learned

We never had any experience with server-side rendering with Node.js so we learned Pug. It was a bit weird to use at first but it made templating really easy once we really got into it. Although we didnt implement it, we learned to use the Plaid API which is really detailed in scraping transactions.

What's next for Budget for a Cause

We plan to implement the Plaid API fully to scrape transactions to be really accurate. We plan to implement a payment processing system using Vantiv or Stripe. Lastly we hope to focus on growing this idea much further.
",http://www.budgetforacause.com,,"JP Morgan Chase & Co. - Best Hack for Social Good, Fifth Third Bank - Best Fin Tech Solution","javascript, amazon-web-services, python, plaid",,University of Cincinnati,3,801-5,University of Cincinnati,"",""
Never Expire,https://revuc-vii.devpost.com/submissions/89940-never-expire,Submitted (Gallery/Visible),Pending,,03/04/2018 13:26:50,"Inspiration

What it does

It reduces food wastage by being notified by when things are expiring.

How I built it

Challenges I ran into

Accomplishments that I'm proud of

What I learned

What's next for Never Expire
",https://github.com/emignj/uchackathon2018,,"","javascript, html5, css3",,University of Cincinnati,0,801-15,University of Cincinnati,"",""
Dementia Helper,https://revuc-vii.devpost.com/submissions/89941-dementia-helper,Submitted (Gallery/Visible),Pending,,03/04/2018 13:27:00,"Inspiration

About a decade ago, my grandma started getting dementia. At first, she would forget details about me and other family members, but then it started to get worse--to the point where she would forget my name. My family felt a lot of pain in being forgotten by someone we truly loved. However, in reality, my grandma was the one going through the most. I wanted to build an app that would help alleviate this stress.

What it does

With a computer and webcam set up in a patients room, this app uses facial recognition to identify loved ones from a database of faces. It uses text-to-speech to announce to the patient who has arrived in the room. It gives their name, their relation, and a quick blurb about who they are

How we built it

We built it using Flask, javascript, face_recogniton in python, and Amazon Polly.

Challenges we ran into

Our main issues we faced were in data transfer and storage of the faces to our online database. It had to capture and encode the faces and efficiently store them for use in later recognition.

Accomplishments that we're proud of

We're very proud we got this to work, especially with Amazon Polly. 

What we learned

What's next for Dementia Helper

We want to further improve upon the mechanism for primary caregivers to input meaningful information for the patients. We want to build a portal to give the caregivers full access to helping the patients. 

Other features: 
An alert that says when a patient hasn't been visited in awhile. 
An end of the day summary of visits
",https://github.com/kolimisi/DimentiaHelper.git,,"JP Morgan Chase & Co. - Best Hack for Social Good, TCS - Best Hardware Hack","python, flask, amazon-polly",,Wright State University,1,801A-2,"Wright State, University of Cincinnati","",""
Altruist,https://revuc-vii.devpost.com/submissions/89942-altruist,Submitted (Gallery/Visible),Pending,,03/04/2018 13:27:29,"Vision

Serve more people by helping them in all possible means

Inspiration

To help people in need of help with people willing to help

What it does

The primary purpose of the app is to serve for a social cause i.e., it connects Donors with recipients and fulfill recipient needs especially during natural disasters

How we built it

We used android-sdk to take in donor information and store it in database using rest endpoints developed in Node. When a person seeking some kind of help(examples: seeking food, seeking shelter during floods, in need of blood etc), he checks in the app with his needs. We used Google location service(FCM) to show the list of nearest donors to the recipient.

Challenges we ran into

Using Google FCM
Integrating android application with REST endpoints

Accomplishments that we're proud of

consistent effort
Teamwork
using various technologies like AWS, Node, Android, FCM
Data Modelling for SQL

What we learned

being together as a team
adapting to dynamic working conditions
new technologies like Android and FCM

What's next for Altruist

The app itself has endless possibilities. Although its currently developed to connect individual donors with individual recipients, it can bring in various NGO's and charities into it's circle. Our ultimate vision is to serve more people by helping them in all possible means. The other side of the coin is to prevent the fraudulent use of the service which itself is a ocean.
","https://github.com/PavanUlichi/Altruist, https://github.com/Purushotham-Reddy-Cheerla/DHope.git",,"JP Morgan Chase & Co. - Best Hack for Social Good, Amazon Web Services - Best Use of AWS","node.js, android-studio, android, atom, github, amazon-web-services, amazon-ec2, mysql, express.js, rest, firebase",,"",0,801M-2,University of Cincinnati,AWS,""